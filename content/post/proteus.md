---
author: mvader
date: 2016-12-22
title: "Proteus, keeping Go as the source of truth"
description: "We are releasing proteus, a tool to generate protobuf files taking Go as the source of truth instead of the other way around."
categories: ["technical"]
---

## Introduction

At source{d} we've been doing Go for almost two years. Until the machine learning came, Go was the only language in which we needed to ouse our data models. Right now, with Python playing a bigger role in our platform and Scala joinin as another player we need to start thinking how to effectively and performantly share our data and data models across all those languages, and the others, in case we would start using more.

We chose protocol buffers as the serialization format for this exchange of data. Usually, people create their `.proto` files where they define their models, enumerations, services and so on, and then the models in every specific language are generated taking from those `.proto` files.

For us, there is a big problem with that approach: **code generated is not idiomatic** for any of the languages (take a look at the python code generated by any proto file and you will understand).

Instead of following this approach, we thought of something: what if we choose the language with the bigger role in our codebase and use it as the source of truth instead? That way, at least one of the language has idiomatic models and code. This language was Go.

## Proteus

Because of the aforementioned reason, we started working on [proteus](https://github.com/src-d/proteus), a tool that scans Go packages and generates `.proto` files from them.

**How does it work?**

* Scans all structs that have the comment `//proteus:generate` and generates them as protobuf messages.
* Scans all the type definitions with the comment `//proteus:generate` and their constant values and transforms them into proper protobuf enumerations.
* Resolves the types and ignores what it can't.
* Converts it to protobuf structures and writes the `.proto` files.

So, imagine you have the following code:

```go
package models

import "time"

type Model struct {
        ID        int64
        CreatedAt time.Time
}

type User struct {
        Model
        Status             Status
        Username           string
        Password           string
        NotCryptedPassword string `proteus:"-"`
}

type Status int

const (
        Pending  Status = iota
        Active
        Inactive
)
```

That code will become the following protobuf file:

```
syntax = "proto3";
package models;

import "google/protobuf/timestamp.proto";

message User {
        int64 id = 1;
        google.protobuf.Timestamp created_at = 2;
        models.Status status = 3;
        string username = 4;
        string password = 5;
}

enum Status {
        PENDING = 0;
        ACTIVE = 1;
        INACTIVE = 2;
}
```

You can check for a more detailed example in the [examples folder](https://github.com/src-d/proteus/tree/master/example).

## Next steps

### Marshal and unmarshal

Proteus is far from finished yet. If you haven't noticed, there is one obvious thing missing from this: how do you convert your structs to and from protobuf? We have not generated any `Marshal` or `Unmarshal` method.

We are working on that feature in our fork of [`gogo/protobuf`](https://github.com/gogo/protobuf). Instead of generating everything from the generated `.proto` file. We drop all that's generated by `protoc` and only leave the marshal and unmarshal methods.

### gRPC service generation

Right now, you can use the gRPC extension of protobuf to generate the server interface if your services (which have to be defined in your proto file as well). Remember we don't want to have protos as source of truth but Go code.

Proteus will be extended to also generate services with the exported methods and functions.

But, just as it happened with marshal and unmarshal, we still need `protoc` to generate the gRPC server interface. What's the good part? Proteus will also generate the gRPC server implementation that implements the interface generated by `protoc`.

### Plugins

Go 1.8 will introduce support for plugins will be added to the language. We want to make all the process completely hackable via plugins. You can do that already by making your own custom `proteus` binary instead of using the provided command, but it will be nicer to just be able to do so with plugins.

## Why not drop the need of `protoc`?

`gogo/protobuf` is more battle-tested and the encode/decode functions they provide are fast, plus it's already done. Same happens with the gRPC server interface.

The only thing we are implementing in proteus is what we thing it's missing: keeping Go as a source of truth for messages, enumerations and services.

Yes, it introduces two steps instead of just one. But it has several advantages:

* Your Go code will be written to you, totally abstracted from protobuf.
* You don't have to write the gRPC server that satisfies the generated interface.

In the end, the two steps of generating can be automated in a `Makefile` or with `go generate`, which is fine for us. Not having idiomatic code in our models, which are the very core of our codebase, was not.
